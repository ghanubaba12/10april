{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0076506-1c72-44e8-9113-33e0d536a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "ans-We can use Bayes' theorem to calculate the probability of an employee being a smoker given that he/she uses the health insurance plan. Let S denote the event that an employee is a smoker, and H denote the event that an employee uses the health insurance plan. Then, we have:\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H)\n",
    "\n",
    "where P(S) is the prior probability of an employee being a smoker, P(H|S) is the probability of an employee using the health insurance plan given that he/she is a smoker, and P(H) is the overall probability of an employee using the health insurance plan.\n",
    "\n",
    "From the problem statement, we know that P(H) = 0.7 (since 70% of employees use the health insurance plan). We also know that P(S|H) is what we want to calculate.\n",
    "\n",
    "Using the information provided, we can calculate P(H|S) as follows:\n",
    "\n",
    "P(H|S) = 0.4\n",
    "\n",
    "Since we don't have information about the overall proportion of smokers in the employee population, we can assume that P(S) is equal to the proportion of employees who use the plan and are smokers, which is:\n",
    "\n",
    "P(S) = (0.7) * (0.4) = 0.28\n",
    "\n",
    "Now we can substitute these values into Bayes' theorem to get:\n",
    "\n",
    "P(S|H) = (0.4) * (0.28) / (0.7)\n",
    "\n",
    "Simplifying, we get:\n",
    "\n",
    "P(S|H) = 0.16\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.16, or 16%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8614d-8273-4413-b945-4e995f294845",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "ans-Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm that are commonly used in text classification.\n",
    "\n",
    "The main difference between them is the way they model the features (i.e., the words or tokens) in the text.\n",
    "\n",
    "Bernoulli Naive Bayes assumes that the features are binary (i.e., they are either present or absent in the document). It models the probability of each feature given each class using a Bernoulli distribution, which is a probability distribution for binary variables. Bernoulli Naive Bayes is often used for document classification tasks where the presence or absence of a word is more important than its frequency.\n",
    "\n",
    "Multinomial Naive Bayes, on the other hand, assumes that the features are count-based (i.e., they represent the frequency of each word in the document). It models the probability of each feature given each class using a Multinomial distribution, which is a probability distribution for discrete variables with a finite number of possible values. Multinomial Naive Bayes is often used for text classification tasks where the frequency of each word is important.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes is suitable for binary data and is often used for document classification tasks where the presence or absence of a word is more important, while Multinomial Naive Bayes is suitable for count-based data and is often used for text classification tasks where the frequency of each word is important.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd4e4f-cf30-41df-a97f-03cae8c2682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "ans-In Bernoulli Naive Bayes, missing values are typically treated as a separate category or a separate class.\n",
    "\n",
    "For example, if a feature can take on the values of 0 or 1 (i.e., binary), a missing value can be represented as a third category, such as \"?\". Then, the probability of a missing value can be estimated using the training data, and this probability can be used to make predictions for new instances with missing values.\n",
    "\n",
    "Alternatively, missing values can be imputed using various methods, such as mean imputation or mode imputation, before applying Bernoulli Naive Bayes. However, this approach assumes that the missing values are missing completely at random and may not always be appropriate for all types of missing data.\n",
    "\n",
    "It is important to note that the handling of missing values in Bernoulli Naive Bayes, or any other machine learning algorithm, can have a significant impact on the accuracy and reliability of the resulting model. Careful consideration and appropriate handling of missing values is necessary to ensure the validity of the model and its predictions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b58a3f-1a7f-4533-9903-8127793c0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "ans-Yes, Gaussian Naive Bayes can be used for multi-class classification. In this case, the algorithm models the probability distribution of each feature for each class using a Gaussian distribution, and then uses Bayes' theorem to compute the probability of each class given a new instance with a set of feature values.\n",
    "\n",
    "To extend Gaussian Naive Bayes for multi-class classification, the algorithm uses the \"one-vs-all\" (OvA) approach. In OvA, the algorithm trains a separate binary classifier for each class by comparing it to all the other classes. For example, for a 3-class classification problem, the algorithm would train three binary classifiers: one for class A vs. classes B and C, one for class B vs. classes A and C, and one for class C vs. classes A and B. To predict the class of a new instance, the algorithm applies each binary classifier to the instance and selects the class with the highest probability.\n",
    "\n",
    "Therefore, Gaussian Naive Bayes can be used for multi-class classification by using the \"one-vs-all\" approach.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbdbeb-4c9b-41e2-a671-f5228fb8f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work.\n",
    "\n",
    "ans-As an AI language model, I am not able to download and run scripts to perform the task assigned to me. However, I can provide a general outline of the steps that you can follow to complete this task:\n",
    "\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase).\n",
    "\n",
    "Load the dataset into a pandas dataframe or any other suitable data structure.\n",
    "\n",
    "Split the dataset into training and testing sets using a suitable strategy (e.g., 80/20 split).\n",
    "\n",
    "Import the necessary libraries from scikit-learn for Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers.\n",
    "\n",
    "Define the classifiers and fit them to the training data.\n",
    "\n",
    "Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. Compute the accuracy, precision, recall, and F1 score for each fold.\n",
    "\n",
    "Compute the average performance metrics over the 10 folds for each classifier.\n",
    "\n",
    "Compare the performance metrics of the three classifiers and identify which variant of Naive Bayes performed the best.\n",
    "\n",
    "Discuss the results obtained, including any limitations of Naive Bayes that you observed.\n",
    "\n",
    "Summarize your findings and provide suggestions for future work, such as exploring other variants of Naive Bayes or using other machine learning algorithms to improve the classification performance.\n",
    "\n",
    "In general, Bernoulli Naive Bayes is suitable for binary input features, Multinomial Naive Bayes is suitable for count-based input features, and Gaussian Naive Bayes is suitable for continuous input features. The choice of which variant of Naive Bayes to use depends on the nature of the input features and the specific problem at hand. It is also important to note that Naive Bayes has limitations, such as the assumption of feature independence and sensitivity to imbalanced datasets.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98035817-1fa5-4ef5-b718-c84b62664d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996292e-158a-42ed-bd85-94adddd73295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92184980-558d-4d0f-90d8-2b700908cc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4670547-4c45-4e15-80a8-f86036ada7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
